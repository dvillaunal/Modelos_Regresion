---
lang: es
format: 
  pdf:
    geometry: margin=1in
highlight-style: tango

editor: source

execute:
  cache: True
  warning: False
---

```{r}
#| message: false
#| echo: false

library(tidyverse)
library(magrittr)
library(janitor)
library(skimr)
library(DataExplorer)
library(GGally)
library(reticulate)
library(stringr)
library(gridExtra)
library(xtable)
library(kableExtra)
library(knitr)
library(corrplot)
library(pander)
library(psych)
library(olsrr)
library(forcats)

source("https://raw.githubusercontent.com/NelfiGonzalez/Regresion-DOE/main/FuncionesdeUsuarioRLM.R")
```

\begin{titlepage}
    \begin{center}
        {\LARGE \textbf{Universidad Nacional De Colombia}} \\
        
        \vspace{4mm}
        
        {\Large \textbf{Sede Medellín}}
        \vspace{0.3cm}
        \begin{figure}[h]
            \centering
        \includegraphics[height=5cm]{logo.jpg}
        \end{figure}
    
    \vspace{1mm}
    
    {\LARGE \textbf{Facultad de Ciencias}}
    \vspace{5mm}
    
    {\Large Departamento de Estadística}
    \vspace{1.4cm}

    {\LARGE\textbf{Proyecto - 3 Entrega}}
    \vspace{1.4cm}    
    
    {\Large \textbf{Daniel Felipe Villa Rengifo}}
    \vspace{4mm}
    
    {\Large \textbf{Luis David Hernández Pérez}}
    \vspace{4mm}
    
    {\Large \textbf{Juan Gabriel Carvajal Negrete}}
    \vspace{1.4cm}
    
    {\Large Modelos de Regresión}
    \vspace{0.5cm}
    
    {\Large\textbf{Febrero, 2025}}

    \end{center}
\end{titlepage}

# Contexto de los datos

## Planteamiento de Problema

Una empresa automotriz china, Geely Auto, tiene la intención de ingresar al mercado de Estados Unidos estableciendo una planta de fabricación allí y produciendo vehículos localmente para competir con sus contrapartes estadounidenses y europeas.

Para ello, han contratado una consultora automotriz para comprender los factores que influyen en la fijación de precios de los vehículos. Específicamente, desean entender los factores que afectan el precio de los autos en el mercado estadounidense, ya que estos pueden ser muy diferentes a los del mercado chino. La empresa desea conocer:

-   Qué variables son significativas para predecir el precio de un automóvil.
-   Qué tan bien estas variables describen el precio de un automóvil.

A partir de diversas encuestas de mercado, la consultora ha recopilado un conjunto de datos <https://www.kaggle.com/datasets/hellbuoy/car-price-prediction/data> sobre diferentes tipos de vehículos en el mercado estadounidense.

## Objetivo Empresarial

Se requiere modelar el precio de los automóviles utilizando las variables independientes disponibles. Este modelo será utilizado por la gerencia para comprender cómo varían exactamente los precios en función de las variables independientes. De esta manera, podrán ajustar el diseño de los vehículos, la estrategia empresarial, entre otros, para alcanzar ciertos niveles de precio. Además, el modelo será una herramienta útil para que la gerencia entienda la dinámica de precios de un nuevo mercado.

## Descripcion de las variables

-   `Car_ID`: ID único de cada observación (entero).
-   `Symboling`: Clasificación del riesgo de seguro; un valor de +3 indica que el automóvil tiene alto riesgo y un valor de -3 indica que probablemente es seguro (categórico).
-   `fueltype`: Tipo de combustible del automóvil, por ejemplo, gasolina o diésel (categórico).
-   `aspiration`: Tipo de aspiración utilizado en el automóvil (categórico).
-   `doornumber`: Número de puertas del automóvil (categórico).
-   `carbody`: Tipo de carrocería del automóvil (categórico).
-   `drivewheel`: Tipo de tracción (ruedas motrices) del automóvil (categórico).
-   `enginelocation`: Ubicación del motor del automóvil (categórico).
-   `wheelbase`: Distancia entre los ejes del automóvil (numérico).
-   `carlength`: Longitud del automóvil (numérico).
-   `carwidth`: Ancho del automóvil (numérico).
-   `carheight`: Altura del automóvil (numérico).
-   `curbweight`: Peso del automóvil sin ocupantes ni equipaje (numérico).
-   `enginetype`: Tipo de motor del automóvil (categórico).
-   `cylindernumber`: Número de cilindros del motor (categórico).
-   `enginesize`: Tamaño del motor del automóvil (numérico).
-   `fuelsystem`: Sistema de combustible del automóvil (categórico).
-   `boreratio`: Relación de diámetro del cilindro (numérico).
-   `stroke`: Carrera o volumen dentro del motor (numérico).
-   `compressionratio`: Relación de compresión del motor (numérico).
-   `horsepower`: Potencia del motor en caballos de fuerza (numérico).
-   `peakrpm`: Revoluciones máximas por minuto (RPM) del motor (numérico).
-   `citympg`: Rendimiento de combustible en ciudad, medido en millas por galón (numérico).
-   `highwaympg`: Rendimiento de combustible en carretera, medido en millas por galón (numérico).
-   `price`: Precio del automóvil, considerado como la variable dependiente (numérico).

```{r}
#| echo: false
datos <- read.csv("CarPrice_Assignment.csv") #carga de los datos
datos %<>% clean_names() # limpieza de los nombres de las variables
```

El conjunto de datos está formado por 205 registros y 26 variables, sin valores ausentes en las variables.

# Limpieza de los datos

En la variable `car_name` podemos observar que los valores almacenan tanto el nombre de la empresa como el nombre del coche por lo cual hay 147 categorias distintas. Por tanto limpiaremos esa variable separarando los nombres de las empresas de carros de la variable `car_name`. Por lo tanto crearemos una variable llamada `company_name` la cual tendra solo el nombre de la empresa o compañia a la cual pertenece el carro.

```{r}
#| echo: false
#| results: hide

# Extrayendo la primera palabra de 'CarName'
datos$company_name <- sapply(strsplit(as.character(datos$car_name), " "), `[`, 1)

datos$company_name %>% unique()
```

Vemos que hay algunas categorías de la variable `company_name` estan mal escritas como:

-   maxda = mazda
-   Nissan = nissan
-   porsche = porcshce
-   toyota = toyouta
-   vokswagen = volkswagen = vw

Reemplazaremos los nombres incorrectos con el nombre correcto de la empresa.

```{r}
#| echo: false
#| results: hide
       
datos$company_name <- str_replace(datos$company_name, 'maxda', 'mazda')
datos$company_name <- str_replace(datos$company_name, 'porcshce', 'porsche')
datos$company_name <- str_replace(datos$company_name, 'toyouta', 'toyota')
datos$company_name <- str_replace(datos$company_name, 'vokswagen', 'volkswagen')
datos$company_name <- str_replace(datos$company_name, 'vw', 'volkswagen')
datos$company_name <- str_replace(datos$company_name, 'Nissan', 'nissan')
```

# Análisis descriptivo de los datos.

Para el análisis exploratorio de datos, y dado el gran número de variables disponibles, se seleccionarán aquellas que, según la investigación previa, podrían ser relevantes para explicar el comportamiento del precio. En este análisis se evaluará la correlación entre las variables numéricas, así como su relación con la variable precio. Para las variables categóricas, se analizará su interacción con el precio, buscando patrones o asociaciones significativas, por tanto las variables que probablemente sean más importantes para predecir el precio de un automóvil:

-   **Dimensiones del vehículo**: Las variables `wheelbase`, `carlength`, `carwidth`, y `carheight` podrían estar correlacionados con el precio porque un automóvil más grande o más espacioso tiende a ser más caro.

-   **Especificaciones del motor**: Variables como `enginesize`, `horsepower`, y `compressionratio` están directamente relacionados con el rendimiento del automóvil y podrían influir significativamente en el precio.

-   **Peso**: La variable `curbweight` puede ser un buen indicador del tipo y tamaño del vehículo, y suele correlacionarse con el precio.

-   **Eficiencia de combustible**: Las variables `citympg` y `highwaympg` podrían influir en el precio, ya que los automóviles más eficientes suelen tener precios diferentes según el segmento de mercado.

La variables categóricas como `carbody`, `drivewheel`, `fueltype`,`enginetype` y `company_name` suelen ser indicadores del tipo de vehículo y su mercado objetivo.



## Variable respuesta

```{r}
#| layout-ncol: 2
#| echo: false
#| label: fig-precio
#| fig-cap: "Distribución de la variable respuesta (Precio)"
#| fig-subcap: 
#|   - "Histograma"
#|   - "Boxplot"


# Grafico del Histograma
ggplot(datos, aes(x = price)) +
  geom_histogram(aes(y = ..density..), 
                 bins = 20, 
                 fill = "steelblue", 
                 alpha = 0.5, 
                 color = "black") +
  geom_density(color = "blue", size = 1) +
  labs(
    x = "Precio",
    y = "Densidad"
  ) +
  theme_minimal()



# Grafico de Boxplot

ggplot(datos, aes(y = price)) +
  geom_boxplot(
    fill = "#458B74",      
    color = "black",    
    outlier.color = "black",
    outlier.size = 2    
  ) +

  labs(
    y = "Precio",
    x = NULL
  ) +
  theme_minimal()
```

<!-- Mejorar esta redaccion -->

De la @fig-precio podemos decir que los precios de los carros tienen una distribución asimétrica, concentrándose en valores bajos, pero con una minoría de carros significativamente más caros, debido a la distribucion puede exister porblemas de normalidad.Los valores atípicos en el rango superior deben considerarse, ya que pueden representar carros de lujo o especiales por tanto análizaremos ahora la variable que corresponde al nombre de la empresa o compañia a la cual pertenece el carro para ver que relación existe con el precio.

```{r}
#| echo: false

# Seleccionamos solo variables numéricas
data_numeric <- datos %>% 
  select(wheelbase, carlength, carwidth, carheight, enginesize, horsepower,
         curbweight, compressionratio,price)
```

\newpage

```{r}
#| echo: false
#| label: fig-corr
#| fig-cap: "Grafico de Correlación"

corr <- cor(data_numeric, method = "pearson")

corrplot(corr,
         method = "circle",            
         type = "upper",               
         tl.col = "black",             
         tl.srt = 45,                  
         number.cex = 0.7,             
         addCoef.col = "black",        
         col = colorRampPalette(c("red", "white", "blue"))(200),
         diag = FALSE)
```

De la @fig-corr se pueden extraer las siguientes conclusiones:

-   Las variables que tienen una mayor relacion lineal con el precio son : `enginesize` ($r=0.87$), `curbweight` ($r = 0.84$) , `horsepower` ($r = 0.81$) y `carwidth` ($r= 0.76$).

-   Hay pares de variables que tienen correlacion alta como `Enginesize` y `horsepower`: 0.8098 ,`Wheelbase` y `carlength`: 0.8746 , `Carlength` y `curbweight`: 0.8777 por lo que posiblemente no sea útil introducir algunas pares de variables en el modelo para evitar multicolinealidad.


\newpage

```{r}
#| echo: false
#| label: fig-empresa
#| fig-cap: "Distribución de los nombre de la empresa"


datos %>% count(company_name) %>% 
  ggplot(aes(x=reorder(factor(company_name), n, decreasing = TRUE), 
             y = n,fill = company_name)) + 
  geom_bar(stat = "identity") +
  labs(
    x = "Nombre de la empresa",
    y = "Frecuencia"
  )+
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1), 
    legend.position = "none")
```

De la @fig-empresa, observamos que la mayoria de los carros en este conjunto de datos está dominado por unas pocas marcas, especialmente Toyota, que supera ampliamente a las demás,por lo tanto, podemos decir que Toyota es la empresa preferida de los clientes.



```{r}
#| layout-ncol: 2
#| echo: false
#| label: fig-empresa2
#| fig-cap: "Distribución del Precio vs Nombre de la empresa"
#| fig-subcap: 
#|   - "Gráfico Boxplot"
#|   - "Gráfico de Barras"


datos %>% ggplot(aes(x = company_name, y=price, fill = company_name))+
  geom_boxplot()+
  theme_minimal()+
    labs(title = "Boxplot Precio vs Nombre de la empresa",
    x = "Nombre de la empresa",
    y = "Precio")+
  theme(
    legend.position = "none",
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.text.x = element_text(angle = 45, hjust = 1))



datos %>% group_by(company_name) %>% 
  summarise(mean_price = mean(price))%>% 
  ggplot(aes(x = reorder(company_name, mean_price, decreasing = TRUE), 
             y=mean_price, fill = company_name))+
  geom_bar(stat = "identity")+
  theme_minimal()+
  labs(title = "Precio promedio vs Nombre de la empresa",
    x = "Nombre de la empresa",
    y = "Precio Promedio")+
  theme(
    legend.position = "none",
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.text.x = element_text(angle = 45, hjust = 1))
```

A partir de la @fig-empresa2 , observamos una diferencia significativa en el precio de los carros según la empresa a la que pertenecen. **Jaguar** y **Buick** parecen ofrecer los carros con las gamas de precios más altas.

\newpage

```{r}
#| layout-ncol: 2
#| echo: false
#| label: fig-disp
#| fig-cap: "Gráficos de dispersión"
#| fig-subcap: 
#|   - "Price vs wheelbase"
#|   - "Price vs carlength"


datos %>% ggplot(aes(x = carlength, y = price)) +
      geom_point(color = "red", alpha = 0.6) +
    labs(y = "Precio",
       x = "Longitud del carro")+
      theme_minimal()

datos %>% ggplot(aes(x = carwidth, y = price)) +
      geom_point(color = "red", alpha = 0.6) +
      labs(y = "Precio",
       x = "Ancho del carro")+
      theme_minimal()
```

De la @fig-disp se observa claramente que la longitud y la anchura del carro están estrechamente relacionadas con su precio.A medida que aumentan la longitud y la anchura del carro, también tiende a aumentar su precio.Sin embargo, no es posible hacer inferencias claras basadas únicamente en la relación entre la longitud y el precio, debido a la alta dispersión de los datos.La altura del carro no parece tener un impacto significativo en el precio.



```{r}
#| layout-ncol: 2
#| echo: false
#| label: fig-disp2
#| fig-cap: "Gráficos de dispersión"
#| fig-subcap: 
#|   - "Price vs citymgp"
#|   - "Price vs highwaympg"


datos %>% ggplot(aes(x = citympg, y = price)) +
      geom_point(color = "red", alpha = 0.6) +
    labs(y = "Precio",
       x = "Rendimiento de combustible en ciudad")+
      theme_minimal()

datos %>% ggplot(aes(x = highwaympg, y = price)) +
      geom_point(color = "red", alpha = 0.6) +
      labs(y = "Precio",
       x = "Rendimiento de combustible en carretera")+
      theme_minimal()
```

De la @fig-disp2 se observa claramente que `citympg` y `highwaympg` tienen una correlación negativa con el precio del carro. A medida que aumentan los valores de `citympg` y `highwaympg`, el precio del carro tiende a disminuir. Dado que ambas características están relacionadas con el precio de manera significativa, `citympg` y `highwaympg` son características útiles para predecir el precio de los carros.

\newpage

```{r}
#| layout-ncol: 2
#| echo: false
#| label: fig-disp3
#| fig-cap: "Gráficos de dispersión"
#| fig-subcap: 
#|   - "Price vs wheelbase"
#|   - "Price vs curbweight"


datos %>% ggplot(aes(x = wheelbase, y = price)) +
      geom_point(color = "red", alpha = 0.6) +
    labs(y = "Precio",
       x = "Distancia entre los ejes del carro")+
      theme_minimal()

datos %>% ggplot(aes(x = curbweight, y = price)) +
      geom_point(color = "red", alpha = 0.6) +
      labs(y = "Precio",
       x = "Peso del carro sin ocupantes ni equipaje")+
      theme_minimal()
```

De la @fig-disp3 se observa claramente que el peso del carro en vacío tiene una alta correlación ($0.84$) con el precio del carro. A medida que aumenta el peso en vacío, el precio del carro también incrementa de manera significativa. Aunque la distancia entre ejes y el precio no presentan una correlación tan alta, todavía existe una relación positiva. Por lo tanto, un aumento en la distancia entre ejes también está asociado con un incremento en el precio del carro.

\newpage

```{r}
#| layout-ncol: 2
#| echo: false
#| label: fig-bar
#| fig-cap: "Gráfico de barras"
#| fig-subcap: 
#|   - "carbody"
#|   - "average price vs carbody"


datos %>% ggplot(aes(x = factor(carbody))) +
    geom_bar(fill = "steelblue") +
    theme_minimal()+
  labs(x = "Tipo de carrocería del carro",
       y = "Frecuencia")

  

datos %>%
    group_by(carbody) %>%
    summarise(avg_price = mean(price, na.rm = TRUE)) %>%
    arrange(desc(avg_price)) %>% 
    ggplot(aes(x = carbody, y = avg_price)) +
    geom_bar(stat = "identity", fill = "coral") +
    theme_minimal() +
    labs(x = "Tipo de carrocería del carro",
       y = "Precio Promedio")

```

De la @fig-bar se observa que los carros con carrocería sedán son los más vendidos, seguidos por los hatchback.Por otro lado, los descapotables y los de techo rígido tienen menores ventas. Estos últimos son también los más caros, seguidos de los descapotables. Es importante señalar que los descapotables y los carros con techo rígido se venden menos debido a su alto costo, lo que los hace menos atractivos para la mayoría de los clientes. Aunque la carrocería sedán ocupa el tercer lugar en términos de precio, sigue siendo la más popular, lo que sugiere que los clientes prefieren carros de gama media.

```{r}
#| layout-ncol: 2
#| echo: false
#| label: fig-bar2
#| fig-cap: "Gráfico de barras"
#| fig-subcap: 
#|   - "enginetype"
#|   - "average price vs enginetype"


datos %>% ggplot(aes(x = factor(enginetype))) +
    geom_bar(fill = "steelblue") +
    theme_minimal()+
  labs(x = "Tipo de motor del carro",
       y = "Frecuencia")

  

datos %>%
    group_by(enginetype) %>%
    summarise(avg_price = mean(price, na.rm = TRUE)) %>%
    arrange(desc(avg_price)) %>% 
    ggplot(aes(x = enginetype, y = avg_price)) +
    geom_bar(stat = "identity", fill = "coral") +
    theme_minimal() +
    labs(x = "Tipo de motor del carro",
       y = "Precio Promedio")
```

De la @fig-bar2 observamos que la mayoría de los carros vendidos tienen motores de árbol de levas en cabeza (OHC).Solo se ha vendido un carro con motor DOHCV, y existen muy pocos datos disponibles para los motores DOHCV y de rotor. Los carros con motores DOHCV son, en su mayoría, más caros. Por otro lado, los carros con motores OHC son los menos costosos.

\newpage

```{r}
#| layout-ncol: 2
#| echo: false
#| label: fig-bar3
#| fig-cap: "Gráfico de barras"
#| fig-subcap: 
#|   - "enginetype"
#|   - "average price vs enginetype"


datos %>% ggplot(aes(x = factor(fueltype))) +
    geom_bar(fill = "steelblue") +
    theme_minimal()+
  labs(x = "Tipo de combustible del carro",
       y = "Frecuencia")

  

datos %>%
    group_by(fueltype) %>%
    summarise(avg_price = mean(price, na.rm = TRUE)) %>%
    arrange(desc(avg_price)) %>% 
    ggplot(aes(x = fueltype, y = avg_price)) +
    geom_bar(stat = "identity", fill = "coral") +
    theme_minimal() +
    labs(x = "Tipo de combustible del carro",
       y = "Precio Promedio")
```

De la @fig-bar3 podemos deducir que los carros con sistema de combustible a gas son los más preferidos, ademas se obeerva que el precio medio de los carros a gasolina es inferior al de los carros a diésel. Por lo tanto, podemos inferir que los clientes tienden a preferir carros que consumen menos combustible.


# Conclusión

Después de realizar el análisis descriptivo, observamos que algunas variables parecen tener una mayor influencia en la explicación del precio de los automóviles, mientras que otras presentan una relación menos significativa. Además, identificamos que, en ciertas variables categóricas, algunas categorías tienen un número reducido de observaciones, lo que podría limitar su representatividad en los análisis posteriores. Por ello, será importante evaluar cómo estas características afectan la interpretación y robustez de los resultados.

<!-- segunda entrega -->

# Segunda Entrega

## Punto 1

Ajuste un modelo de regresión lineal múltiple únicamente con las covariables continuas, muestre la tabla de parámetros ajustados y escriba la ecuación ajustada. Calcule la Anova del modelo ¿Es significativo el modelo? ¿Que proporción de la variabilidad total de la respuesta es explicada por el modelo? Opine sobre esto ultimo.

```{r}
# seleccion de variables continuas
var_continuas <- datos %>% 
  select(wheelbase, carlength, carwidth, carheight, boreratio, stroke,
         compressionratio, price)
# Ajuste del modelo con las variables continuas
mod_cont <- lm(price ~., data = var_continuas)
```

```{r}
#| echo: false
#| label: tbl-parametros
#| tbl-cap: Parámetros ajustados
summary(mod_cont)$coefficients %>% kable(digits = 3)
```

El modelo ajustado es:

$$
\hat{Y} = -130372.23 - 120.34X_1 + 181.66X_2 + 2142.93X_3 -480.86X_4 + 3782.87X_5 -1181.08X_6 -23.42X_7
$$

```{r}
MiAnova(mod_cont)
```

Del resultado de la tabla anova podemos concluir que

\begin{itemize}
    \item El modelo es altamente significativo globalmente (\( p < 2.2 \times 10^{-16} \)).
    \item Las variables significativas individuales son \texttt{carlength}, \texttt{carwidth}, \texttt{carheight} y \texttt{boreratio}.
    \item El modelo explica el \( 62.48\% \) de la variabilidad en los precios, lo que lo convierte en un modelo razonablemente efectivo, aunque con espacio para mejorar.
\end{itemize}

## Punto 2

Calcule los coeficientes de regresión estandarizados y concluya acerca de cual de las variables aporta mas a la respuesta según la magnitud en valor absoluto de tales coeficientes (cuidado, no confunda esto con la significancia de los coeficientes de regresión).

\newpage

```{r}
#| label: tbl-parametros2
#| echo: false
#| message: false
#| warning: false
#| tbl-cap: Coeficientes estimados y Coeficientes estimados estandarizados

miscoeficientes(mod_cont)[c(1,5)] %>% kable()
```

De la @tbl-parametros2 podemos concluir con respecto a los coeficientes estandarizados.

-   La variable `carwidth` es, con diferencia, la variable que tiene el mayor aporte a la respuesta, según la magnitud absoluta.

-   Las variables `compressionratio` y `stroke` aportan muy poco a la respuesta.

## Punto 3

Pruebe la significancia individual de cada uno de los parámetros del modelo (excepto intercepto), usando la prueba t, establezca claramente la prueba de hipótesis y el criterio de decisión.

La hipotesis para la prueba t de la significancia individual de cada uno de los parametros $\beta_j$ (excepto el intercepto $\beta_0$):esta dada por:

$$
H_0 : \beta_j = 0 \quad vs \quad H_1 : \beta_j \neq 0
$$

Mediante el siguiente estadístico de prueba con su distribución bajo $H_0$ y criterios de rechazo:

$\text{Estadístico de prueba: } T_0 = \frac{\hat{\beta}_j}{\sqrt{\text{MSE} \, C_{jj}}} \overset{H_0}{\sim} t_{n-k-1}$

$\text{Rechazo con valor P: si } P(|t_{n-k-1}| > |T_0|) \text{ es pequeño};$

$\text{Rechazo con región crítica a un nivel de significancia } \alpha: \text{ si } |T_0| > t_{\alpha/2, n-k-1}$.

De la @tbl-parametros observamos las variables `carlength` , `carwidth`, `carheight` y `boreratio` son significativas.

## Punto 4

Teniendo en cuenta los resultados anteriores, realice una prueba con sumas de cuadrados extras con test lineal general; especifique claramente el modelo reducido y completo, estadístico de la prueba, su distribución, cálculo de valor P, decisión y conclusión a la luz de los datos. Justifique la hipótesis que desea probar en este numeral.

Teniendo encuenta el resultado anterior tenemos que la hipotesis a probar es:

\begin{itemize}
    \item \( H_0 \): Las variables significativas identificadas en la Tabla 1 (\texttt{carlength}, \texttt{carwidth}, \texttt{carheight} y \texttt{boreratio}) no contribuyen significativamente al modelo.
    \item \( H_1 \): Al menos una de estas variables contribuye significativamente al modelo.
\end{itemize}

El modelo completo(MF):

\begin{align*}  
Y_i = \beta_0 + \beta_1 \text{\texttt{wheelbase}} + \beta_2 \text{\texttt{carlength}} + \beta_3 \text{\texttt{carwidth}} + \beta_4 \text{\texttt{carheight}} + \\ \beta_5
\text{\texttt{boreratio}} + \beta_6 \text{\texttt{stroke}} + \beta_7 \text{\texttt{compressionratio}} + \epsilon
\end{align*}

El modeloreducido(MR):

\begin{equation*}
Y_i = \beta_0 + \beta_1 \text{\texttt{wheelbase}} + \beta_6 \text{\texttt{stroke}} + \beta_7 \text{\texttt{compressionratio}} + \epsilon
\end{equation*}

\textbf{Especificación de la prueba:}

\begin{itemize}
    \item El estadístico de prueba utilizado es el estadístico \( F \), definido como:
    \[
    F = \frac{\text{(RSS\_reducido - RSS\_completo) / (p\_completo - p\_reducido)}}{\text{RSS\_completo / (n - p\_completo)}}
    \]
    donde:
    \begin{itemize}
        \item \text{RSS\_reducido}: Suma de cuadrados residuales del modelo reducido.
        \item \text{RSS\_completo}: Suma de cuadrados residuales del modelo completo.
        \item \( p \): Número de parámetros en el modelo.
        \item \( n \): Número de observaciones.
    \end{itemize}
    \item El estadístico \( F \) sigue una distribución \( F \) de Fisher con:
    \[
    \text{gl\_numerador} = p\_completo - p\_reducido = 4, \quad \text{gl\_denominador} = n - p\_completo = 197
    \]
\end{itemize}

```{r}

# Ajuste del modelo completo
MF <- lm(price ~ wheelbase + carlength + carwidth + carheight + 
                      boreratio + stroke + compressionratio, 
         data = var_continuas)

linearHypothesis(MF, c("carlength=0", "carwidth=0", "carheight=0",
                       " boreratio=0"))
```

De la salida anterior podemos concluir que:

Dado que el valor $p$ es mucho menor que 0.05, rechazamos la hipótesis nula $H_0$. Esto significa que al menos una de las variables \texttt{carlength}, \texttt{carwidth}, \texttt{carheight} o \texttt{boreratio} tiene un impacto significativo en la variable dependiente (\texttt{price}).

Las variables \texttt{carlength}, \texttt{carwidth}, \texttt{carheight} y \texttt{boreratio} contribuyen significativamente al modelo. Por lo tanto, deben incluirse en el modelo para explicar adecuadamente la variabilidad de la variable dependiente (\texttt{price}).

## Punto 5

Construya y analice gráficos de los residuales estudentizados vs. Valores ajustados y contra las variables de regresión utilizadas. ¿Que información proporcionan estas gráficas?

\newpage

```{r}
#| echo: false
#| layout-ncol: 3

# Residuales estudentizados
residuales_estudentizados <- rstudent(mod_cont)

# Valores ajustados
valores_ajustados <- fitted(mod_cont)

# Gráfico 1: Residuales estudentizados vs. Valores ajustados
plot(valores_ajustados, residuales_estudentizados,
     main = "Residuales estudentizados vs. Valores ajustados",
     xlab = "Valores ajustados",
     ylab = "Residuales estudentizados",
     pch = 19, col = "blue")
abline(h = 0, col = "red", lwd = 2)  # Línea horizontal en 0

# Gráficos 2: Residuales estudentizados vs. Variables independientes
variables <- names(mod_cont$model)[-1]  # Nombres de las variables independientes

for (var in variables) {
  plot(mod_cont$model[[var]], residuales_estudentizados,
       main = paste("Residuales estudentizados vs.", var),
       xlab = var,
       ylab = "Residuales estudentizados",
       pch = 19, col = "blue")
  abline(h = 0, col = "red", lwd = 2)  # Línea horizontal en 0
}

```

Del gráfico anterior podemos decir que

-   Los gráficos sugieren que podría haber problemas de varianza no constante (heterocedasticidad), especialmente en los extremos de los valores ajustados y en variables como `boreratio` y `compressionratio`.

-   En variables como `stroke`, el patrón observado podría indicar que una relación no lineal no está siendo capturada.

-   Hay algunos puntos extremos (residuales estudentizados vs. Valores ajustados) que podrían estar influyendo en el modelo.

## Punto 6

Construya una gráfica de probabilidad normal para los residuales estudentizados. ¿Existen razones para dudar de la hipótesis de normalidad sobre los errores en este modelo?

\newpage

```{r}
#| echo: false
#| label: fig-QQ
#| fig-cap: "Gráfico Q-Q Residuales Estudentizados"

# Calcular los residuales estudentizados
residuales_estudentizados <- rstudent(mod_cont)

# Crear el QQ plot
qqnorm(residuales_estudentizados)
qqline(residuales_estudentizados, 
       col = "red", 
       lwd = 2)
```

De la @fig-QQ observamos posibles indicios de que los errores podrían no seguir perfectamente una distribución normal debido a la desviación de algunos puntos en los extremos.

## Punto 7

Diagnostique la presencia de observaciones atípiacs, de balanceo y/o influenciales y concluya.

Para esto utilizaremos la función `influencePlot()`.

```{r}
#| eval: false
#| echo: true

influencePlot(mod_cont)
```



```{r}
#| echo: false
#| results: asis
#| label: tbl-diagnostico
#| tbl-cap: Observaciones potencialmente influyentes, de balanceo y/o atípiacs 

cat("
\\begin{table}
\\centering
\\begin{tabular}{cccc}
\\hline
\\textbf{Index} & \\textbf{StudRes} & \\textbf{Hat} & \\textbf{CookD} \\\\ \\hline
28 & 4.20659283 & 0.0584620 & 1.266128e-01 \\\\
29 & 4.92766935 & 0.0584620 & 1.685452e-01 \\\\
30 & 0.01077858 & 0.1803456 & 3.211570e-06 \\\\
35 & 0.22152729 & 0.2372586 & 1.917390e-03 \\\\ \\hline
\\end{tabular}
\\end{table}
")
```

```{r}
#| echo: false
#| results: asis
#| label: tbl-ubral
#| tbl-cap: Valores de umbrales (Threshold values)


cat("
\\begin{table}
\\centering
\\begin{tabular}{ccccccc}
\\hline
\\textbf{Threshold values} & \\textbf{dfbeta} & \\textbf{dffit} & \\textbf{cov.r} & \\textbf{Cook.d} & \\textbf{hat} & \\textbf{StudRes} \\\\ \\hline
1 & 0.1396861 & 0.3950918 & 0.1170732 & 0.02030457 & 0.07804878 & 2 \\\\ \\hline
\\end{tabular}
\\end{table}
")
```

De la @tbl-diagnostico podemos concluir que:

-   Las observaciones 28 y 29 son outliers claros según sus residuales estandarizados y podrían requerir mayor análisis o tratamiento.

-   Las observaciones 30 y 35 aunque no son outliers extremos, tienen valores de leverage moderadamente altos, lo que indica que podrían tener un impacto significativo en el modelo.

## Punto 8

Suponga que algunas de las observaciones que presentaron problemas en el numeral anterior son por problemas de digitación, elimínelas (no mas de 10) y ajuste el modelo de regresión sin dichas observaciones. Presente solo la tabla de parámetros ajustados resultante ¿Cambian notoriamente las estimaciones de los parámetros, sus errores estandar y/o la signficancia? ¿Que concluye al respecto? Evalué el gráfico de normalidad para los residuales estudentizados para este ajuste ¿mejoro la normalidad? Concluya sobre los efectos de estas observaciones.

```{r}
#| echo: true
# Crear un nuevo conjunto de datos sin las filas problemáticas
data_clean <- var_continuas[-c(28, 29, 30, 35), ]
# Modelo ajustado sin las observaciones problemáticas
mod_cont1 <- lm(price ~., data = data_clean)
```



```{r}
#| echo: false
#| label: tbl-parametros1
#| tbl-cap: Parámetros nuevo ajuste

summary(mod_cont1)$coefficients %>% kable(digits = 3)
```

De la @tbl-parametros y @tbl-parametros1 podemos concluir:

Las variables más afectadas por el nuevo ajuste son:

-   `carlength`: Aumentó en magnitud y significancia, indicando que las observaciones eliminadas podrían haber reducido su importancia en el modelo original.

-   `boreratio`: Mantuvo su relevancia y mostró un leve aumento en magnitud y significancia.

En general, no hubo cambios drásticos en los parámetros, lo que indica que el modelo era relativamente robusto frente a las observaciones eliminadas.

-   Los errores estándar se mantuvieron similares, lo que sugiere que las eliminaciones no afectaron de manera significativa la estabilidad del modelo.

-   No se perdieron variables significativas tras el ajuste. De hecho, `carlength` mostró una mayor relevancia en el nuevo modelo.

-   Las observaciones eliminadas tenían un impacto limitado en el modelo general, aunque influían ligeramente en la significancia y magnitud de algunas variables clave, como `carlength` y `boreratio`.




```{r}
#| echo: false
#| label: fig-QQ2
#| fig-cap: "Gráfico Q-Q Residuales Estudentizados (nuevo ajuste)"


# Calcular los residuales estudiantizados
residuales_est1 <- rstudent(mod_cont1)

# Gráfico Q-Q
qqnorm(residuales_est1)
qqline(residuales_est1, col = "red")
```

De la @fig-QQ2 vemos que todavia hay algunos puntos que se alejan signifcativamente de la línea recta (en particular en los extremos), lo cual podemos decir de que no hay mejoria en la normalidad, por lo tanto se podria optar por elimninar esas obervaciones.

<!-- Entrega 3 -->

# Tercera Entrega

Realice las siguientes actividades con todas las covariables y sin las observaciones que excluyó en el último punto de la segunda entrega.

Teniendo en cuenta el ultimo entrega las observaciones problemas son las observaciones 28, 29, 30, y 35.

Dado que tenemos un gran numero de variables tanto numericas como categoricas, algunas con muchos niveles y algunos de esos niveles con pocas observaciones, basandonos en investigaciones previas consideraremos a ajustar el modelo considerando todas las variables numericas ya que pueden ser de relevancia en el precio de los carros.

\newpage

## Punto 1

Realice diagnósticos de multicolinealidad mediante.

```{r}
#| echo: false
# datos sin las observaciones problemas
datos_03 <- datos[-c(28,29,30,35),-c(1,2)]


datos_03 <- datos_03 %>%  select_if(is.numeric)

# datos_03<- datos_03 %>% select_if(function(x) is.numeric(x) & !is.integer(x))

# datos_03 <- datos_03 %>% mutate_if(is.character, as.factor)
# datos_03$symboling %<>% as.factor() 
```

```{r}
#| echo: false


# datos_03 <- datos_03 %>%
#   mutate(symboling = fct_lump_n(symboling, n = 2,
#                                      other_level = "otros"))
# 
# table(datos_03$symboling)
# 
# 
# 
# datos_03 <- datos_03 %>%
#   mutate(carbody = fct_lump_n(carbody, n = 2,
#                                      other_level = "otros"))
# 
# table(datos_03$carbody)
# 
# 
# 
# datos_03 <- datos_03 %>%
#   mutate(enginetype = fct_lump_n(enginetype, n = 2, 
#                                    other_level = "otros"))
# 
# table(datos_03$enginetype)
# 
# 
# datos_03 <- datos_03 %>%
#   mutate(cylindernumber = fct_lump_n(cylindernumber, n = 2, 
#                                      other_level = "otros"))
# 
# table(datos_03$cylindernumber)
# 
# 
# datos_03 <- datos_03 %>%
#   mutate(fuelsystem = fct_lump_n(fuelsystem, n = 2, 
#                                      other_level = "otros"))
# table(datos_03$fuelsystem)
```

### Matriz de correlación de las variables predictoras

```{r}
#| label: fig-corplot
#| echo: false
#| fig-cap: Gráfico de Correlaciones

corr_03 <- cor(datos_03[,-14],method = "pearson")

corrplot(corr_03,
         method = "number",            
         type = "upper",
         tl.cex = 0.6,
         tl.col = "black",                  
         number.cex = 0.6,             
         addCoef.col = "black",        
         col = colorRampPalette(c("red", "white", "blue"))(200),
         diag = FALSE)
```

De acuerdo a la @fig-corplot podemos concluir que:

-   Se observan correlaciones altas entre pares de variables:
    -   carlength y wheelbase (0.88).
    -   carwidth y curbweight (0.85).
    -   enginesize y horsepower (0.81).
-   Estas correlaciones nos sugieren que podría haber multicolinealidad en el modelo de regresión si se incluyen estas variables juntas.

\newpage

### VIF's

```{r}
#| include: false
# Ajuste del modelo co las variables numericas
modelo <- lm(price ~.,data = datos_03)
summary(modelo)
```

```{r}
#| echo: false
#| label: tbl-vifs
#| tbl-cap: "Factores de inflación de varianza (VIF) para las variables predictoras del modelo"


vif(modelo) %>% kable(col.names = c("Predictores","VIF"),align = c('c'))
```

De acuerdo a la @tbl-vifs hay probema de multicolinealidad severa en algunas variables.

### Indice de condición

```{r}
#| echo: false
#| label: tbl-ic
#| tbl-cap: "Índice de condición para las variables predictoras del modelo"

multicolin(modelo, center = TRUE)[4] %>% kable(align = c('c'))
```

Según la @tbl-ic hay valores del índice de condición mayores a 10, y menores a 30 lo que indica que hay problemas de multicolinealidad moderada entre las variables predictoras.

\newpage

### Proporciones de varianza.

```{r}
#| echo: false
#| label: tbl-pv
#| tbl-cap: "Proporciones de varianza para las variables predictoras del modelo"


multicolin(modelo, center = TRUE)[,c(3,5,6,7,8,9,10)] %>% 
  kable(align = c('ccccccc'), digits = 4)
```

Según la @tbl-pv hay proporciones $\pi_{ij}$ altas $(> 0.5)$ para dos o más coeficientes de regresión asociados con un mismo valor propio pequeño, por tanto hay evidencia de multicolinealidad entre las variables correspondientes a tales coeficientes.

## Punto 2

Construya modelos de regresión utilizando los métodos de selección (muestre de cada método sólo la tabla de resumen de este y la tabla ANOVA y la de parámetros estimados del modelo finalmente resultante):

\newpage

### Selección según el $R^2_{adj}$

```{r}
#| echo: false
#| label: tbl-Radj
#| tbl-cap: "Selección de Modelos según el Estadístico $R^2_{adj}$"
# Generar todos los modelos posibles
k <- ols_step_all_possible(modelo)

# Mejor modelo segun R2 adj
k$result %>% select(predictors, adjr) %>% arrange(-adjr) %>% head() %>% 
  kable(digits = 3, align = c('lc'))
```

Según la @tbl-Radj podemos concluir que:

Algunos modelos seleccionados explican el 84.1% de la variabilidad de la respuesta (( R\^2\_{adj} = 0.841 )), lo que indica que diferentes combinaciones de predictores tienen un rendimiento estadístico similar.

### Selección según el estadístico $C_p$

```{r}
#| echo: false
#| label: tbl-cp
#| tbl-cap: "Selección de Modelos según el Estadístico $C_p$"


# Mejor modelo segun Cp

k$result %>% select(predictors, cp) %>% arrange(cp) %>% head() %>% 
  kable(digits = 3, align = c('lc'))
```

Según la @tbl-cp podemos concluir que:

-   La selección de modelos utilizando el estadístico ( C_p ) proporciona resultados consistentes con los modelos más parsimoniosos. A continuación, se destacan los hallazgos:

-   El modelo con el menor valor de ( C_p ) (9.516) incluye las siguientes variables: \texttt{carwidth}, \texttt{curbweight}, \texttt{enginesize}, \texttt{stroke}, \texttt{compressionratio}, \texttt{horsepower} y \texttt{peakrpm}. Esto indica que es el modelo más eficiente en términos de ajuste y complejidad.

### Stepwise

```{r}
#| eval: false
#| include: false
ols_step_both_p(modelo,p_enter = 0.05,p_remove = 0.05, details = TRUE)
```

### Stepwise Summary

| Step | Variable             | AIC      | SBC      | SBIC     | R²      | Adj. R² |
|------|----------------------|----------|----------|----------|---------|---------|
| 0    | Base Model           | 4188.440 | 4195.046 | 3614.935 | 0.00000 | 0.00000 |
| 1    | enginesize (+)       | 3898.712 | 3908.621 | 3326.831 | 0.76575 | 0.76458 |
| 2    | curbweight (+)       | 3872.598 | 3885.811 | 3300.808 | 0.79633 | 0.79427 |
| 3    | peakrpm (+)          | 3850.004 | 3866.520 | 3278.670 | 0.81979 | 0.81704 |
| 4    | stroke (+)           | 3842.894 | 3862.714 | 3271.764 | 0.82777 | 0.82426 |
| 5    | compressionratio (+) | 3834.705 | 3857.828 | 3264.022 | 0.83628 | 0.83209 |
| 6    | horsepower (+)       | 3831.216 | 3857.643 | 3260.869 | 0.84069 | 0.83577 |
| 7    | carwidth (+)         | 3827.563 | 3857.292 | 3257.681 | 0.84511 | 0.83950 |
| 8    | curbweight (-)       | 3829.548 | 3855.974 | 3259.317 | 0.84201 | 0.83713 |

: Resumen Stepwise {#tbl-stepwise}

### ANOVA Table

| Source     | Sum of Squares  | DF  | Mean Square    | F       | Sig.   |
|------------|-----------------|-----|----------------|---------|--------|
| Regression | 10895045813.356 | 6   | 1815840968.893 | 172.323 | 0.0000 |
| Residual   | 2044262318.091  | 194 | 10537434.629   |         |        |
| Total      | 12939308131.447 | 200 |                |         |        |

: ANOVA Stepwise {#tbl-stepwise_anova}

| Variable | Beta | Std. Error | Std. Beta | t | Sig. | Lower Bound | Upper Bound |
|---------------|:-------:|:-------:|:------:|-------|:-----:|:--------|--------:|
| (Intercept) | -61651.158 | 10967.630 |  | -5.621 | 0.000 | -83282.258 | -40020.058 |
| enginesize | 118.085 | 12.651 | 0.615 | 9.334 | 0.000 | 93.135 | 143.035 |
| peakrpm | 2.252 | 0.646 | 0.133 | 3.487 | 0.001 | 0.978 | 3.525 |
| stroke | -2817.179 | 775.921 | -0.110 | -3.631 | 0.000 | -4347.502 | -1286.856 |
| compressionratio | 262.483 | 68.598 | 0.130 | 3.826 | 0.000 | 127.189 | 397.777 |
| horsepower | 39.662 | 12.800 | 0.196 | 3.098 | 0.002 | 14.416 | 64.907 |
| carwidth | 770.751 | 166.440 | 0.206 | 4.631 | 0.000 | 442.488 | 1099.015 |

: Parámetros estimados del modelo final Stepwise {#tbl-stepwise_parametros}

### Selección hacia adelante o forward

```{r}
#| eval: false
#| include: false
ols_step_forward_p(modelo,p_val=0.05,details =TRUE)
```

| Step | Variable         | AIC      | SBC      | SBIC     | R²      | Adj. R² |
|------|------------------|----------|----------|----------|---------|---------|
| 0    | Base Model       | 4188.440 | 4195.046 | 3614.935 | 0.00000 | 0.00000 |
| 1    | enginesize       | 3898.712 | 3908.621 | 3326.831 | 0.76575 | 0.76458 |
| 2    | curbweight       | 3872.598 | 3885.811 | 3300.808 | 0.79633 | 0.79427 |
| 3    | peakrpm          | 3850.004 | 3866.520 | 3278.670 | 0.81979 | 0.81704 |
| 4    | stroke           | 3842.894 | 3862.714 | 3271.764 | 0.82777 | 0.82426 |
| 5    | compressionratio | 3834.705 | 3857.828 | 3264.022 | 0.83628 | 0.83209 |
| 6    | horsepower       | 3831.216 | 3857.643 | 3260.869 | 0.84069 | 0.83577 |
| 7    | carwidth         | 3827.563 | 3857.292 | 3257.681 | 0.84511 | 0.83950 |

: Resumen Forward {#tbl-forward}

| Source     | Sum of Squares  | DF  | Mean Square    | F       | Sig.   |
|------------|-----------------|-----|----------------|---------|--------|
| Regression | 10935177611.572 | 7   | 1562168230.225 | 150.439 | 0.0000 |
| Residual   | 2004130519.875  | 193 | 10384095.958   |         |        |
| Total      | 12939308131.447 | 200 |                |         |        |

: ANOVA Forward {#tbl-forward_anova}

| Variable | Coeficiente | Error Estándar | Beta Estandarizado | t | p -value | Intervalo de Confianza (95%) |
|-----------------|:-------:|:-------:|:-------:|:-------:|:-----:|----------:|
| (Intercepto) | -49384.392 | 12548.844 |  | -3.935 | 0.000 | \[-74134.874, -24633.909\] |
| `enginesize` | 110.052 | 13.206 | 0.573 | 8.333 | 0.000 | \[84.006, 136.099\] |
| `curbweight` | 2.347 | 1.194 | 0.153 | 1.966 | 0.051 | \[-0.008, 4.701\] |
| `peakrpm` | 2.503 | 0.654 | 0.148 | 3.829 | 0.000 | \[1.214, 3.792\] |
| `stroke` | -2758.629 | 770.830 | -0.107 | -3.579 | 0.000 | \[-4278.962, -1238.296\] |
| `compressionratio` | 240.409 | 69.017 | 0.120 | 3.483 | 0.001 | \[104.285, 376.533\] |
| `horsepower` | 31.735 | 13.331 | 0.157 | 2.381 | 0.018 | \[5.442, 58.029\] |
| `carwidth` | 502.674 | 214.229 | 0.135 | 2.346 | 0.020 | \[80.143, 925.205\] |

: Parámetros estimados del modelo final Forward {#tbl-forward_parametros}

### Selección hacia atrás o backward

```{r}
#| eval: false
#| include: false
ols_step_backward_p(modelo,p_val=0.05,details = TRUE)
```

| Step | Variable Removed | AIC      | SBC      | SBIC     | R²      | Adj. R² |
|------|------------------|----------|----------|----------|---------|---------|
| 0    | Full Model       | 3831.642 | 3881.192 | 3263.314 | 0.85110 | 0.84075 |
| 1    | boreratio        | 3830.295 | 3876.542 | 3261.728 | 0.85061 | 0.84108 |
| 2    | curbweight       | 3829.532 | 3872.475 | 3260.665 | 0.84969 | 0.84094 |
| 3    | highwaympg       | 3828.548 | 3868.188 | 3259.435 | 0.84893 | 0.84098 |
| 4    | wheelbase        | 3828.221 | 3864.557 | 3258.816 | 0.84767 | 0.84049 |
| 5    | carlength        | 3827.575 | 3860.608 | 3257.943 | 0.84664 | 0.84025 |
| 6    | citympg          | 3828.062 | 3857.792 | 3258.139 | 0.84473 | 0.83910 |
| 7    | carheight        | 3829.548 | 3855.974 | 3259.317 | 0.84201 | 0.83713 |

: Resumen Backward {#tbl-backward}

| Source     | Sum of Squares  | DF  | Mean Square    | F       | Sig.   |
|------------|-----------------|-----|----------------|---------|--------|
| Regression | 10895045813.356 | 6   | 1815840968.893 | 172.323 | 0.0000 |
| Residual   | 2044262318.091  | 194 | 10537434.629   |         |        |
| Total      | 12939308131.447 | 200 |                |         |        |

: ANOVA Backward {#tbl-backward_anova}

| Variable | Coeficiente | Error Estándar | Beta Estandarizado | t | p-value | Intervalo de Confianza (95%) |
|-----------------|:---------:|:---------:|:---------:|:-------:|:-----:|----------:|
| (Intercepto) | -61651.158 | 10967.630 |  | -5.621 | 0.000 | \[-83282.258, -40020.058\] |
| `carwidth` | 770.751 | 166.440 | 0.206 | 4.631 | 0.000 | \[442.488, 1099.015\] |
| `enginesize` | 118.085 | 12.651 | 0.615 | 9.334 | 0.000 | \[93.135, 143.035\] |
| `stroke` | -2817.179 | 775.921 | -0.110 | -3.631 | 0.000 | \[-4347.502, -1286.856\] |
| `compressionratio` | 262.483 | 68.598 | 0.130 | 3.826 | 0.000 | \[127.189, 397.777\] |
| `horsepower` | 39.662 | 12.800 | 0.196 | 3.098 | 0.002 | \[14.416, 64.907\] |
| `peakrpm` | 2.252 | 0.646 | 0.133 | 3.487 | 0.001 | \[0.978, 3.525\] |

: Parámetros estimados del modelo final Backward {#tbl-backward_parametros}


## Punto 3

Teniendo en cuenta los resultados del numeral anterior y los supuestos del modelo, ¿Cuál modelo sugiere para la variable respuesta? ¿por qué?

El modelo más adecuado sería el **Backward**, ya que produce un modelo más parsimonioso (con menos variables). Además, ninguno de los tres modelos obtenidos mediante los métodos del numeral anterior cumple con los supuestos. Por lo tanto, las variables seleccionadas en el modelo **Backward** son: *carwidth, enginesize, stroke, compressionratio, horsepower* y *peakrpm*.



```{r}
mod_backward <- lm(price~carwidth+enginesize+stroke+compressionratio+
                     horsepower+peakrpm, data = datos_03)
```



## Punto 4


Con el modelo que seleccionó en el numeral anterior realice una intervalo de respuesta media y de predicción al 90% para la variable de respuesta. Justifique claramente la selección de los valores de las covariables. Realice las pruebas pertinentes para llevar a cabo este numeral.

Escogeremos la media de cada variable debido a que representa un automóvil promedio dentro de la muestra de datos, ademas permite obtener una predicción que es representativa del conjunto de datos.



```{r}
#| include: false
# Seleccionar valores representativos (media de cada variable)
valores_covariables <- data.frame(
  carwidth = mean(datos_03$carwidth),
  enginesize = mean(datos_03$enginesize),
  stroke = mean(datos_03$stroke),
  compressionratio = mean(datos_03$compressionratio),
  horsepower = mean(datos_03$horsepower),
  peakrpm = mean(datos_03$peakrpm)
)

# Calcular intervalos de confianza y predicción al 90%
pred_conf <- predict(mod_backward, newdata = valores_covariables, interval = "confidence", level = 0.90)
pred_pred <- predict(mod_backward, newdata = valores_covariables, interval = "prediction", level = 0.90)



# Mostrar resultados
print("Intervalo de confianza al 90% (Media esperada)")
print(pred_conf)

print("Intervalo de predicción al 90% (Para una nueva observación)")
print(pred_pred)
```

| Tipo de Intervalo             | Estimación (fit) | Límite Inferior (lwr) | Límite Superior (upr) |
|-------------------------------|------------------|-----------------------|-----------------------|
| **Intervalo de confianza 90%** | 13,354          | 12,975.58             | 13,732.42             |
| **Intervalo de predicción 90%**| 13,354          | 7,975.62              | 18,732.37             |



: Intervalos de confianza y predicción



    
    
    
    
    
    
    
    
    
    