---
format: pdf
execute: 
  fig-align: center 
  cache: true
editor: source
editor_options: 
  chunk_output_type: inline
---

```{r}
#| include: false 
#| warning: false
library(car)
library(rsm)
library(rgl)
library(scatterplot3d)
library(GGally)
library(xtable)
library(magrittr)
library(glue)
library(pander)
library(kableExtra)
library(tidyverse)
```



\begin{titlepage}
	\begin{center}
		{\LARGE \textbf{Universidad Nacional De Colombia}} \\
		
		\vspace{4mm}
		
		{\Large \textbf{Sede Medellín}}
		\vspace{0.3cm}
		\begin{figure}[h]
			\centering
		\includegraphics[height=5cm]{logo.jpg}
		\end{figure}
	
	\vspace{1mm}
	
	{\LARGE \textbf{Facultad de Ciencias}}
	\vspace{5mm}
	
    {\Large Departamento de Estadística}
	\vspace{1.4cm}

    {\LARGE\textbf{Taller RML (Parte 1) - Grupo 4}}
    \vspace{1.4cm}    
    
    {\Large \textbf{Daniel Felipe Villa Rengifo}}
    \vspace{4mm}
    
    {\Large \textbf{Luis David Hernández Pérez}}
    \vspace{4mm}
    
    {\Large \textbf{Juan Gabriel Carvajal Negrete}}
    \vspace{1.4cm}
	
    {\Large Modelos de Regresión}
	\vspace{1cm}
    
    {\Large\textbf{Diciembre, 2024}}

	\end{center}
\end{titlepage}




## Punto 1

Realice una descripción de la base de datos. Contextualice el problema y explique cada una de las variables involucradas en el modelo. <https://www.codersarts.com/post/predict-boston-house-prices-using-python-linear-regression

## Descripción de la base de datos

Tomaremos el conjunto de datos de Vivienda que contiene información sobre diferentes casas en Boston. Hay 506 muestras y 13 variables de características en este conjunto de datos. El objetivo es predecir el valor de los precios de la casa utilizando las características dadas.

La descripción de todas las características se proporciona a continuación:

-   **CRIM**: tasa de criminalidad per cápita por ciudad

-   **ZN**: proporción de terrenos residenciales zonificados para lotes de más de 25 000 pies cuadrados

-   **INDUS:** proporción de acres de negocios no minoristas por ciudad

-   **CHAS**: variable ficticia de Charles River (= 1 si el terreno limita con el río; 0 en caso contrario) NOX: concentración de óxido nítrico (partes por 10 millones)

-   **RM**: número promedio de habitaciones por vivienda

-   **AGE**: proporción de unidades ocupadas por sus propietarios construidas antes de 1940 DIS: distancias ponderadas a cinco centros de empleo de Boston

-   **RAD**: índice de accesibilidad a carreteras radiales

-   **TAX**: tasa de impuesto a la propiedad de valor total por cada \$10 000

-   **PTRATIO**: proporción de alumnos por maestro por ciudad B: 1000(Bk — 0,63)², donde Bk es la proporción de \[personas de afroamericanas \[descendencia\] por ciudad

-   **LSTAT**: Porcentaje de la población de estatus inferior

-   **MEDV**: Valor medio de las viviendas ocupadas por sus propietarios en miles de dólares

Los precios de las viviendas, representados por la variable **MEDV**, constituyen nuestra variable objetivo. El resto de las variables actuarán como características que utilizaremos para predecir el valor de una vivienda.

# Punto 2

Realice un análisis descriptivo de las variables que se van a tener en cuenta en el modelo. Concluya.

```{r}
#| message: false
#| warning: false
#| echo: false
#| fig-width: 10
#| fig-height: 7
datos <- read.csv("Bases_de_datos/boston.csv")

datos4 <-datos[401:500,c(1,5,6,7,11,13,14)]


ggpairs(datos4)
```

**Correlaciones**: MEDV tiene una fuerte correlación positiva con RM (número promedio de habitaciones por vivienda), lo que indica que las viviendas con más habitaciones tienden a tener un valor más alto. Por otro lado, MEDV tiene una fuerte correlación negativa con LSTAT (porcentaje de la población de estatus inferior), lo que sugiere que las viviendas en áreas con mayor porcentaje de población de bajos ingresos tienden a tener un valor más bajo.

**Otras variables**: CRIM (tasa de criminalidad): Tiene una correlación negativa moderada con MEDV, lo que indica que las viviendas en áreas con mayor criminalidad tienden a tener un valor más bajo.RM (número de habitaciones): Además de su fuerte correlación con MEDV, RM también muestra una correlación positiva con AGE (proporción de unidades ocupadas por sus propietarios construidas antes de 1940). Esto podría indicar que las viviendas más antiguas tienden a tener más habitaciones.LSTAT (porcentaje de población de bajos ingresos): Además de su correlación negativa con MEDV, LSTAT también muestra correlaciones negativas con RM y una correlación positiva con CRIM. Esto sugiere que las áreas con mayor porcentaje de población de bajos ingresos tienden a tener viviendas más pequeñas y mayor criminalidad.

```{r}
#| fig-cap: Distribución de la variable respuesta `MEDV` 
#| message: false
#| warning: false
#| echo: false


datos4 %>% ggplot(aes(x=MEDV))+
  geom_histogram(aes(y=..density..), fill="dodgerblue") +
  geom_density(linewidth = 1.2) +
  theme_bw() +
  theme(axis.title.y = element_blank())
```

Vemos que los valores de la variable `MEDV` se distribuyen no normales y en su mayoría agrupados por lo cual podríamos decir que no hay presencia de datos atípicos.



# Prueba de normalidad

```{r}
#| output-location: slide
#| echo: false

shapiro.test(datos4$MEDV)
```

**Distribución**: Como se nota en la prueba de shapiro, la variable MEDV se distribuye de manera normal, con algunos valores atípicos en el extremo superior. Esto significa que la mayoría de las viviendas tienen un valor medio cercano a la media, con algunas viviendas que tienen valores significativamente más altos.

**Factores influyentes**: El análisis sugiere que el valor medio de las viviendas (MEDV) está influenciado por varios factores, incluyendo el número de habitaciones (RM), el porcentaje de población de bajos ingresos (LSTAT), la tasa de criminalidad (CRIM) y posiblemente la edad de la vivienda (AGE). Sabiendo todo esto, podemos ajustar un modelo de regresión múltiple.

Con base en las observaciones anteriores graficaremos la variable`RM` y `LSTAT` usando un diagrama de dispersión, frente a la variable de respuesta `MEDV`.

```{r}
#| layout-ncol: 2
#| echo: false
#| message: false

datos4 %>% ggplot(aes(y=MEDV, x=RM)) +
  geom_point() +
  geom_smooth(se=F) +
  theme_bw()

datos4 %>% ggplot(aes(y=MEDV, x=LSTAT)) +
  geom_point() +
  geom_smooth(se=F) +
  theme_bw()
```

Podemos notar que los precios de los hogares aumentan a medida que el valor de la variable `RM` aumenta "linealmente". Hay pocos valores atípicos y los datos parecen tener cierto limite en 9.

Los precios tienden a disminuir a medida que aumenta la variable `LSTAT`. aunque no parece seguir exactamente una tendencia lineal "cuadrática o exponencial".


# Punto 3

Ajuste un modelo de regresión lineal múltiple, muestre la tabla de parámetros ajustados y escriba la ecuación ajustada. Calcule la Anova del modelo ¿Es significativo el modelo? ¿Qué proporción de la variabilidad total de la respuesta es explicada por el modelo? Opine sobre esto último.

```{r}
# Modelo de regresión lineal múltiple con todas las variables 
modelo <- lm(MEDV~.,datos4)
```

\begin{table}[h!]
\centering
\caption{resumen del modelo de regresión}
\begin{tabular}{|c|c|c|c|c|}
\hline
\textbf{Coeficientes} & \textbf{Estimación} & \textbf{Error Estándar} & \textbf{Valor t} & \textbf{Pr(>|t|)} \\ \hline
(Intercepto) & 59.06933 & 30.51461 & 1.936 & 0.05593 . \\ \hline
CRIM & -0.08634 & 0.03139 & -2.750 & 0.00715 ** \\ \hline
NOX & -21.92000 & 6.51255 & -3.366 & 0.00111 ** \\ \hline
RM & 0.26285 & 0.80549 & 0.326 & 0.74492 \\ \hline
EDAD & -0.01242 & 0.02954 & -0.421 & 0.67507 \\ \hline
PTRATIO & -1.00533 & 1.59420 & -0.631 & 0.52984 \\ \hline
LSTAT & -0.46531 & 0.08208 & -5.669 & 1.61e-07 * \\ \hline
\end{tabular}
\end{table}

El modelo de regresión lineal presentado busca predecir el valor medio de las viviendas (MEDV) en Boston, encontrando que la criminalidad (CRIM), la contaminación (NOX) y el nivel socioeconómico (LSTAT) son los predictores más importantes, con coeficientes negativos y significativos. Mientras que el número de habitaciones (RM), la edad de las viviendas (AGE) y la calidad de la educación (PTRATIO) no muestran una influencia significativa en este modelo. El intercepto (59.06933) representa el valor estimado de una vivienda cuando todas las variables predictoras son cero, pero debe interpretarse con cautela. Se podrían realizar mejoras al modelo, como eliminar variables no significativas, verificar la multicolinealidad, explorar otras variables relevantes (distancia a empleos, áreas verdes), considerar interacciones entre variables y evaluar posibles relaciones no lineales.

# Ecuación del modelo

$$
\hat{y}_0 = 59.06933 -0.08634x_1 - 21.92000x_2 + 0.26285x_3 - 0.01242x_4 - 1.001242x_5 - 1.00533x_6 - 0.46531x_7 + \epsilon_i
$$

# Tabla de variabilidad del modelo (Tabla Anova)

```{r}
#| echo: false
#| include: false
anova(modelo)
```

\begin{table}[ht]
\centering
\begin{tabular}{lrrrrr}
  \hline
 & Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\ 
  \hline
CRIM & 1 & 583.85 & 583.85 & 48.91 & 0.0000 \\ 
  NOX & 1 & 490.82 & 490.82 & 41.12 & 0.0000 \\ 
  RM & 1 & 112.76 & 112.76 & 9.45 & 0.0028 \\ 
  AGE & 1 & 116.39 & 116.39 & 9.75 & 0.0024 \\ 
  PTRATIO & 1 & 2.48 & 2.48 & 0.21 & 0.6493 \\ 
  LSTAT & 1 & 383.57 & 383.57 & 32.13 & 0.0000 \\ 
  Residuals & 93 & 1110.13 & 11.94 &  &  \\ 
   \hline
\end{tabular}
\end{table}

## **2. Significancia del modelo**
Para determinar si el modelo es significativo, se observa el valor global de $F$ y su p-valor asociado. El modelo tiene un valor $F$ elevado (verificado en la salida de Anova) y un p-valor menor a 0.05, lo que indica que el modelo es globalmente significativo y al menos una de las variables predictoras tiene una relación significativa con $MEDV$.

## **3. Proporción de variabilidad explicada**
El coeficiente de determinación ($R^2$) indica la proporción de la variabilidad total de la respuesta que es explicada por el modelo. En este caso:

$$
R^2 = 1 - \frac{\text{Suma de cuadrados residuales}}{\text{Suma total de cuadrados}}
$$

Con base en la tabla Anova:
- Suma de cuadrados residuales ($SS_{Residuals}$): 1110.13.
- Suma total de cuadrados ($SS_{Total}$): $1110.13 + (583.85 + 490.82 + 112.76 + 116.39 + 2.48 + 383.57) = 2800.00$.

$$
R^2 = 1 - \frac{1110.13}{2800.00} = 0.6035
$$

Por lo tanto, el modelo explica aproximadamente el **60.35%** de la variabilidad total de $MEDV$.

## **4. Opinión sobre $R^2$**
Un valor de $R^2$ del 60.35% sugiere que el modelo posee un nivel de poder explicativo moderado. Aunque no logra explicar toda la variabilidad de $MEDV$, esta situación es comprensible dado que el fenómeno en cuestión está afectado por diversos factores, algunos de los cuales podrían no estar considerados en este análisis. Se podría optimizar el modelo mediante la inclusión de variables adicionales pertinentes, la exploración de posibles relaciones no lineales, o la aplicación de técnicas más sofisticadas como la regularización (LASSO, Ridge) para mejorar la selección de variables.

# Punto 4

Pruebe la significancia individual de cada uno de los parámetros del modelo (excepto intercepto), usando la prueba t, y para dos cualesquiera de las predictoras, establezca claramente la prueba de hipótesis y el criterio decisión.

Para realizar el test de significancia individual para cada uno de los parámetros $\beta_j$j , esto es, probar

$$
H_0 : \beta_j = 0 \ \text{vs.} \ H_1 : \beta_j \neq 0
$$

Teniendo en cuenta además que $\sigma^2$ es desconocido, mediante el siguiente estadístico de prueba con su distribución bajo $H_0$:

$$
T_0 = \frac{\hat{\beta}_j}{\sqrt{\text{MSE} \, C_{jj}}} \overset{H_0}{\sim} t_{n-k-1};
$$

```{r}
#| echo: false
#| label: tbl-resumen
#| tbl-cap: Resumen del modelo
summary(modelo)$coefficients %>% round(5) %>% pander()
```

De acuerdo con la @tbl-resumen, se observa que las variables `CRIM`, `NOX`y  `LSTAT` resultan estadísticamente significativas, dado que sus valores p son menores al nivel de significancia establecido ($\alpha = 0.05$).


Para las variables `CRIM` y `AGE`, establezeremos la prueba de hipótesis y el criterio de
decision.


Para la variable `CRIM` las hipótesis son las siguientes:


$$
H_0 : \beta_1 = 0 \ \text{vs.} \ H_1 : \beta_1 \neq 0
$$

Para la variable `AGE` las hipótesis son las siguientes:


$$
H_0 : \beta_4 = 0 \ \text{vs.} \ H_1 : \beta_4 \neq 0
$$


Y los criterios de desición son:


$$
\text{Rechazo con valor P: si } P\left( \left| t_{n-k-1} \right| > \left| T_0 \right| \right) \text{ es pequeño;}
$$

$$
\text{Rechazo con región crítica a} \\
\text{un nivel de significancia} \ \alpha: \text{ si } \left| T_0 \right| > t_{\alpha/2, n-k-1}
$$



## Punto 5

Teniendo en cuenta los resultados anteriores, realice una prueba con sumas de cuadrados extras utilizando el test lineal general; especifique claramente el modelo reducido y el modelo completo, el estadístico de la prueba, su distribución, el cálculo del valor P, la decisión y la conclusión a la luz de los datos. Justifique la hipótesis que desea probar en este numeral.


Del resultado anterior de la @tbl-resumen se considera considere el test parcial de la significancia de coeficientes asociados a las variables`RM`,`AGE` y` PTRATIO`.


$$
H_0 : \beta_3 = \beta_4 = \beta_5 = 0 \ \text{vs.} \ H_1 : \beta_j \neq 0,\ para\ al\ menos\  un\ j, \ con j=3,4\ y\ 5
$$

En este caso la matriz $L$ corresponde a,



$$
L = 
\begin{bmatrix}
0 & 0 & 0 & 1 & 0 & 0\\
0 & 0 & 0 & 0 & 1 & 0\\
0 & 0 & 0 & 0 & 0 & 1
\end{bmatrix}
$$


- **Modelo Completo (MF)**

```{r}
# Crear el modelo completo
modelo_completo <- lm(MEDV ~ CRIM + NOX + RM +
                        AGE + PTRATIO + LSTAT, data = datos4)
```


$$
Y_i = \beta_0 + \beta_1 \text{CRIM}_i + \beta_2 \text{NOX}_i + \beta_3 \text{RM}_i + \beta_4 \text{AGE}_i + \beta_5 \text{PTRATIO}_i + \beta_6 \text{LSTAT}_i + E_i
$$

- **Modelo Reducido (MR)**


```{r}
# Crear el modelo reducido
modelo_reducido <- lm(MEDV ~ CRIM + NOX + LSTAT, data = datos4)
```


$$
Y_i = \beta_0 + \beta_1 \text{CRIM}_i + \beta_2 \text{NOX}_i + \beta_6 \text{LSTAT}_i + E_i
$$

```{r}
# Realizar prueba de sumas de cuadrados adicionales
anova_result <- anova(modelo_reducido, modelo_completo)

anova_result
```


Por tanto, $SSR(MR) = SSR(X_3, X_4, X_5|X_1, X_2, X_6)$ con $k = 6-3 = 3$ grados de libertad.


```{r}
# Calcular el estadístico F manualmente (opcional, usando los residuos)
# Suma de cuadrados error modelo reducido
SSE_MR <- sum(residuals(modelo_reducido)^2)
# Suma de cuadrados error modelo completo
SSE_MF <- sum(residuals(modelo_completo)^2)
```

Se utiliza el siguiente estadístico:

$$
F_{o,3-4-5} = \frac{SSR(X_3, X_4, X_5|X_1, X_2, X_6)}{MSE(X_1, X_2, X_3, X_4, X_5, X_6)} \sim f_{3,96}
$$

```{r}
# Grados de libertad
n <- nrow(datos4)  # Número de observaciones
q <- 3  # Número de coeficientes restringidos
p <- length(coef(modelo_completo))  # Número de coeficientes modelo completo
df_error <- n - p  # Grados de libertad residuales modelo completo

# Cálculo estadístico F
F_o <- ((SSE_MR - SSE_MF) / q) / (SSE_MF / df_error)

# Valor P asociado
valor_p <- pf(F_o, df1 = q, df2 = df_error, lower.tail = FALSE)
```


con una región de rechazo (calculo del valor-p) donde:

$$
f{3,96} > F_{o,3-4-5}
$$

```{r}
#| echo: false
# Imprimir resultados
cat("Estadístico F:", F_o, "\n")
cat("Valor p:", valor_p, "\n")

# Decisión
if (valor_p < 0.05) {
  cat("Rechazamos H0: Al menos una de las variables (RM, AGE, PTRATIO) es significativa.\n")
} else {
  cat("No rechazamos H0: Las variables (RM, AGE, PTRATIO) no son significativas en conjunto.\n")
}
```

Con base en los resultados de la prueba de hipótesis, el estadístico $F$ calculado es $0.2835$ y el valor $P$ asociado es $0.8372$. Dado que el valor $P$ es considerablemente mayor al nivel de significancia comúnmente utilizado ($\alpha = 0.05$), no se rechaza la hipótesis nula ($H_0$). Esto indica que, en conjunto, las variables $\text{RM}$, $\text{AGE}$ y $\text{PTRATIO}$ no aportan significativamente a la explicación de la variable dependiente, después de considerar las demás variables en el modelo ($\text{CRIM}$, $\text{NOX}$, y $\text{LSTAT}$). 

En consecuencia, estas tres variables podrían ser excluidas del modelo sin perder sustancialmente la capacidad explicativa del mismo.

# Punto 6

Calcule las sumas de cuadrados tipo I (secuenciales) y tipo II (parciales) ¿Cuál de las variables tienen menor valor en tales sumas? ¿Qué puede significar ello?



Expecificando el modelo que estamos trabajando

$$
Y_i = \beta_0 + \beta_1 X_{i1} + \beta_2 X_{i2} + \beta_3 X_{i3} + \beta_4 X_{i4} + \beta_5 X_{i5} + \beta_6 X_{i6} +  E_i, \quad 
E_i \overset{\text{i.i.d.}}{\sim} N(0, \sigma^2)
$$
Utilirizaremos la funcion `anova()` para obtener la suma de cuadrados $SS1$.


```{r}
#| echo: false
#| label: tbl-anova
#| tbl-cap: Sumas de cuadrados tipo I

anova(modelo) %>% kable()
```


De la @tbl-anova podemos concluir que:

- La variable `PTRATIO` tiene la menor suma de cuadrados, lo que implica que su efecto en la variable `MEDV` es muy bajo cuando se incluye después de las demás variables.Esto podría sugerir que su efecto ya está explicado por las otras variables del modelo o que no tiene relacion directamente con la variable respuesta.

- Las variables `CRIM`, `NOX` y `LSTAT` son las más importantes, ya que explican una gran proporción de la varianza en `MEDV` y son altamente significativas.




Para la $SS2$ utilirizaremos la funcion `Anova()` para obtener la suma de cuadrados


```{r}
#| echo: false
#| label: tbl-anova2
#| tbl-cap: Sumas de cuadrados tipo 2

Anova(modelo) %>% kable()
```

De la @tbl-anova2 podemos concluir que:

Las variables CRIM, NOX y LSTAT son las variables con mayor impacto en la variabilidad de MEDV,en particular la variable LSTAT tiene la mayor contribución.

- Las variables `RM`, `AGE` y `PTRATIO` tienen una baja contribución con respecto a la variable `MEDV` una vez que se controlan las otras variables, lo que sugiere que pueden no ser necesarias en el modelo.





## Punto 7

Construya y analice gráficos de los residuales estudentizados vs. Valores ajustados y contra las variables de regresión utilizadas. ¿Qué información proporcionan estas gráficas?

\newpage

```{r}
#| echo: false
#| label: fig-resi
#| fig-cap: "Residuales Estudentizados vs Valores ajustados"


residuales_estudentizados <- rstandard(modelo)


valores_ajustados <- fitted(modelo)


plot(valores_ajustados, residuales_estudentizados, 
     xlab = "Valores Ajustados", ylab = "Residuales Estudentizados")
abline(h = 0, col = "red")

```


La @fig-resi nos dice que:

- E modelo es adecuado, ya que no hay patrones visibles (es decir, los residuales se  distribuyen aleatoriamente alrededor de cero).Esto sugiere que los errores tienen una varianza constante (homocedasticidad) y que el modelo es lineal


- Aunque la mayoría de los puntos están cerca de la línea cero, hay algunos puntos que se encuentran bastante alejados (outliers), especialmente en la parte superior del gráfico.


\newpage


```{r}
#| echo: false
#| label: fig-resi2
#| fig-cap: "Residuales Estudentizados vs Cada Variable"


par(mfrow=c(2,3)) 


plot(datos4$CRIM, residuales_estudentizados, 
     xlab = "CRIM",ylab = "",
     main = "Residuales vs. CRIM")
plot(datos4$NOX, residuales_estudentizados, 
     xlab = "NOX", ylab = "", 
     main = "Residuales vs. NOX")
plot(datos4$RM, residuales_estudentizados, 
     xlab = "RM", ylab = "",
     main = "Residuales vs. RM")
plot(datos4$AGE, residuales_estudentizados, 
     xlab = "AGE", ylab = "",
     main = "Residuales vs. AGE")
plot(datos4$PTRATIO, residuales_estudentizados, 
     xlab = "PTRATIO", ylab = "",
     main = "Residuales vs. PTRATIO")
plot(datos4$LSTAT, residuales_estudentizados, 
     xlab = "LSTAT", ylab = "",
     main = "Residuales vs. LSTAT")

```


De la @fig-resi2 podemos decir que:


- En la mayoría de los gráficos, los residuos se distribuyen de manera aleatoria alrededor de cero, lo que sugiere que el modelo es adecuado para estas variables. No hay patrones claros que sugieran problemas de heterocedasticidad o no linealidad.

- El gráfico de la variable `PTRATIO` con respecto a los residuales presenta unos posibles outliers, lo cual se debe investigar más a fondo para ver si es un error de medición o si representa un caso especial.


- El gráfico de variable `RM` con respectoa los residuales tiene un rango más estrecho, pero igualmente los residuales parecen distribuidos aleatoriamente.


## Punto 8

Construya una gráfica de probabilidad normal para los residuales estudentizados. ¿Existen razones para dudar de la hipótesis de normalidad sobre los errores en este modelo?


\newpage


```{r}
#| echo: false
#| label: fig-resi3
#| fig-cap: "Gráfico Q-Q de Residuales Estudentizados"


qqnorm(residuales_estudentizados)
qqline(residuales_estudentizados, col = "red")
```

De la @fig-resi3 vemos que hay algunos puntos que se alejan significativamente de la línea recta (en particular en los extremos), lo cual hay posibles razonespara dudar de la normalidad de los errores.



# Punto 9

Diagnostique la presencia de observaciones atípicas, de balanceo y/o influenciales y concluya.




## Diagnóstico de observaciones atípicas

Para las observaciones atipicas se considerada atípica si su residuo estudentizado está fuera del rango [-2, 2] o [-3, 3] dependiendo del nivel de tolerancia. Para este caso consideraremos observacion atipicas si esta fuera del rango de [-3, 3].

```{r}
outliers <- which(abs(residuales_estudentizados) > 3)
outliers
```

En este caso, las observaciones 8, 10, 13, 408, 410 y 413 cumplen con este criterio, por tanto son posibles outliers.


## Diagnóstico de observaciones de balanceo


Primeramente calculamos los valores de leverage (diagonales de la matriz $H$), también llamada matriz de proyección).Las observaciones con $h_{ii}$ grandes y residuales $r_i$ también grandes probablemente serán influenciales.

La observación $i$ es un punto de balanceo si $hii > 2(k + 1)/n$, pero si $2(k + 1)/n > 1$, este criterio no funciona pues los $h_{ii}$ siempre son menores que 1.

```{r}
# Calcular valores de leverage
leverage <- hatvalues(modelo)

# Umbral para leverage alto
umbral_leverage <- 2 * ((length(coef(modelo)) + 1) / nrow(datos4))

# Identificar observaciones con leverage alto
balanceo <- which(leverage > umbral_leverage)
print(balanceo)

```


Las observaciones 406, 407, 411, 415, 419, 494, 495, 496, 6, 7, 11, 15, 19, 95 y 96 tienen valores de leverage altos, es decir, estos puntos tienen una influencia considerable en el ajuste del modelo debido a su posición en el espacio de las variables predictoras.


## Diagnóstico de observaciones influenciales

Para este diagnostico utlizaremos la distacia de Cook lo uqe hace es medir la influencia de la observación $i$ sobretodos los valores ajustados de la respuesta, para $i = 1, 2, . . . , n$.Una observación es influyente si su distancia de Cook supera el umbral de $4/n.$


```{r}
# Calcular la distancia de Cook
cook <- cooks.distance(modelo)

# Umbral de influencia
umbral_cook <- 4 / nrow(datos4)

# Identificar observaciones influyentes
influenciales <- which(cook > umbral_cook)
influenciales
```


Estas observaciones tienen un impacto considerable en el modelo. Se debe investigar para decidir si se deben eliminar, ajustar, o conservar, dependiendo de si representan errores o datos extremos válidos. Si representan errores o casos extremos no representativos de la población general, podrían excluirse para mejorar la precisión del modelo. Sin embargo, si son casos válidos, es importante reconocer su impacto y considerar métodos robustos que puedan reducir su influencia sin eliminarlas.


# Punto 10 

Suponga que se establece que hay un error de digitación en un máximo de 10 observaciones. Ajuste el modelo sin esas observaciones y presente solo la tabla de parámetros ajustados resultante. ¿Cambian notablemente las estimaciones de los parámetros, sus errores estándar y/o la significancia? ¿Qué concluye al respecto? Evalúe el gráfico de normalidad para los residuales studentizados de este ajuste. ¿Mejoró la normalidad? Concluya sobre los efectos de estas observaciones.



Supongamos que tenemos 10 observaciones que se consideran como errores de digitación, son las 10 ultimas filas.

```{r}
# se eliminaron las 10 ultimas observacione
datos_limpios <- datos4[-c(91:100), ]
```

\newpage

```{r}
# Ajustar el modelo sin las observaciones problemáticas
modelo_ajustado <- lm(MEDV ~., data = datos_limpios)
```


```{r}
#| echo: false
#| label: tbl-resu_nuevo
#| tbl-cap: Resumen del Nuevo Ajuste del Modelo


summary(modelo_ajustado)$coefficients %>% round(5) %>% kable(align = 'lcccc')
```


De la @tbl-resu_nuevo notamos que si hubo cambios notables las estimaciones de los parámetros en sus errores estándar algunas variables no sufrieron cambios notables , pero otras si como es el caso de la variable `PTRATIO` y con respecto a la significancia la variable que sufrio cambios en su significancia fue `PTRATIO`.



\newpage


```{r}
#| echo: false
#| label: fig-resi_nuevo
#| fig-cap: "Gráfico Q-Q de Residuales Estudentizados Nuevo Ajuste"
residuales_estudentizados_ajustado <- rstudent(modelo_ajustado)
qqnorm(residuales_estudentizados_ajustado)
qqline(residuales_estudentizados_ajustado, col = "red")
```

De la @fig-resi_nuevo vemos que hay algunos puntos que se alejan significativamente de la línea recta (en particular en los extremos), lo cual hay posibles razones para dudar de la normalidad de los errores, por tanto no mejoro la normalidad.







Podemos concluir que, en este caso, las observaciones problemáticas no tuvieron una influencia significativa en los resultados del modelo, ya que las estimaciones de los parámetros , sus errores estándar sufrieron cambios pero no tan notables excepto en una variable y l a significancia estadísticapermanecieron prácticamente inalterados tras su eliminación. Esto  nos sugiere que el modelo es robusto frente a dichas observaciones.

